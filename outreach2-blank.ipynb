{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the \"needle in the haystack\" galaxiesÂ¶\n",
    "A python excersie notebook written by Lewis McMillan, Summer 2020. This notebook has benifited from examples provided by Rita Tojeiro, and the help of Anne-Marie Weijmans, and Simon Reynolds.\n",
    "\n",
    "In this notebook you will use data from the Sloan Digital Sky Survey (SDSS), to explore how astronomers interact with \"big data\", and how they can use various different measurments of galaxies shapes in order to find spiral galaxies, the mergering of multiple galaxies, and other interesting galaxies.\n",
    "\n",
    "## SDSS and SciServer\n",
    "As mentioned above, in this notebook we will use data from SDSS, which is is the largest astronmical dataset in the world currently. For eachs nights observing it generates around 200Gb of data. The laptop this notebook was written on has 256Gb of storage space, meaning that I could fit 1 nights observing data on my laptop with some space left over for all the programs I need to analysie the data.\n",
    "\n",
    "If you are reading this then we assume that you havel alredy followed the instructions to get an account on SciServer, and have uploaded this notebook. In addition to this we assume that you are familiar with basic python, dataframe manipulation, and matplotlib commands. If not please complete Rita Tojeiro's notebook's which cover these topics: link here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pawlikMorphLSST import Image, helpers, pixmap, skyBackground # Library for analysing galaxies\n",
    "print(\"Galaxy analysis code imported\")\n",
    "# move back to original folder\n",
    "\n",
    "# Import Python libraries to work with SciServer\n",
    "import SciServer.CasJobs as CasJobs                 # query with CasJobs\n",
    "import SciServer.SkyServer as SkyServer\n",
    "print('SciServer libraries imported')\n",
    "\n",
    "# Import other libraries for use in this notebook.\n",
    "import numpy as np                                  # standard Python lib for math ops\n",
    "import pandas as pd                                 # data manipulation package\n",
    "import matplotlib.pyplot as plt                     # another graphing package\n",
    "from pathlib import Path                            # manage local files in your Compute containers\n",
    "from astropy.visualization import ZScaleInterval    # for plotting clear images\n",
    "from tqdm import tqdm_notebook                      # for a nice progress bar\n",
    "from concurrent.futures import ProcessPoolExecutor  # for running the code on more than 1 cpu\n",
    "from IPython.display import clear_output            # allow nice printing\n",
    "import json\n",
    "print('Supporting libraries imported')\n",
    "\n",
    "# Apply some special settings to the imported libraries\n",
    "# ensure columns get written completely in notebook\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "# for plotting clear images\n",
    "zscale = ZScaleInterval()\n",
    "\n",
    "# do *not* show python warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Settings applied')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objects in the Sloan Digital Sky Survey's.\n",
    "#\n",
    "# Query the Sloan Digital Sky Serveys' NSA catalog of galactical objects.\n",
    "# For the database schema and documentation see http://skyserver.sdss.org/dr16/en/help/browser/browser.aspx?cmd=description+nsatlas+U#&&history=description+nsatlas+U\n",
    "#\n",
    "# This query finds all galaxies in the value added catalogue PawlikMorph and matches this information to the\n",
    "# MaNGA catalogue in order to get galaxies positions.\n",
    "# Finally we discard any galaxies that have incomplete measurments\n",
    "#\n",
    "# First, store the query in an object called \"query\"\n",
    "query=\"\"\"\n",
    "select distinct m.objra, m.objdec, p.run, p.rerun, p.camcol, p.field\n",
    "from dbo.PawlikMorph p\n",
    "  join dbo.mangaDAPall m\n",
    "  on m.mangaID = p.mangaid\n",
    "\"\"\"\n",
    "\n",
    "#Then, query the database. The answer is a table that is being returned to a dataframe that we've named all_gals.\n",
    "all_gals = CasJobs.executeQuery(query, \"dr16\")\n",
    "\n",
    "print(\"SQL query finished.\")\n",
    "print(f\"SQL query returned {len(all_gals.index)} galaxies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to the dataframe, which contains the path to the image\n",
    "def makename(df):\n",
    "    root = \"/home/idies/workspace/sdss_das/das2/imaging/\"\n",
    "    df[\"fname\"] = df.apply(lambda row: root + f\"{int(row.run)}/{int(row.rerun)}/corr/{int(row.camcol)}/fpC-{int(row.run):06}-r{int(row.camcol)}-{int(row.field):04}.fit.gz\", axis=1)\n",
    "    return df\n",
    "\n",
    "# add filename column\n",
    "all_gals = makename(all_gals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following three snippets of code should only be run once. If your code crashes during the course of this notebook or you complete this notebook over multiple afternoons skip these three snippets and run the 4th cell down from this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet create a list of filenames, and positions that analyseImage requires to run\n",
    "info = []\n",
    "for i in range(0, len(all_gals.index)):\n",
    "    ra, dec = all_gals[\"objra\"].iloc[i], all_gals[\"objdec\"].iloc[i]\n",
    "    name = all_gals[\"fname\"].iloc[i]\n",
    "    info.append([name, ra, dec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processResult(results):\n",
    "    processedResults = {\"A\": [], \"As\": [], \"As90\": [], \"C\": [], \"S\": [], \"g\": [], \"m20\": [], \"fname\": [], \"radec\": []}\n",
    "    for result in results:\n",
    "        if result[0] != -99:\n",
    "            processedResults[\"A\"].append(result[0])\n",
    "            processedResults[\"As\"].append(result[1])\n",
    "            processedResults[\"As90\"].append(result[2])\n",
    "            processedResults[\"C\"].append(result[3])\n",
    "            processedResults[\"S\"].append(result[4])\n",
    "            processedResults[\"g\"].append(result[5])\n",
    "            processedResults[\"m20\"].append(result[6])\n",
    "            processedResults[\"fname\"].append(result[7])\n",
    "            processedResults[\"radec\"].append((result[8], result[9]))\n",
    "    return processedResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cores = 16\n",
    "results = []\n",
    "with ProcessPoolExecutor(max_workers=cores) as pool:\n",
    "    for result in tqdm_notebook(pool.map(helpers.analyseImage, info), total=len(info)):\n",
    "        results.append(result)\n",
    "finalResults = processResult(results)\n",
    "json.dump(finalResults, open(\"results.json\", \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code crashes, or this work is completed over more than one afternoon, you can reload the results using the below code in order to save time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this everytime you open the notebook to load in the results\n",
    "finalResults = json.load(open(\"results.json\"))\n",
    "# convert dictionary to pandas dataframe\n",
    "df = pd.DataFrame.from_dict(finalResults)\n",
    "# print dataframe\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above show the different rows in the dataframe of results calculated using the full galaxy analysis code\n",
    "   - A: The asymmetry of galaxy. This calculated on the image of the galaxy by rotating the image by 180 degrees and subtracting it from the original.\n",
    "   - As: Is the shape asymmetry of the galaxy. This is calculated on the mask of the galaxy by rotating the mask by 180 degrees and subtracting it from the original mask.\n",
    "   - As90: Is the shape asymmetry of the galaxy at 90 degrees. Again this is calculated on the mask of the galaxy.\n",
    "   - C: Is the Concentration of light within the galaxy\n",
    "   - S: Is is the Smoothnees/Clumpiness of the distribution of light in the galaxy.\n",
    "   - g: Is the Gini index of the galaxy.\n",
    "   - m20: Is the $2^{nd}$ moment of light of the galaxy\n",
    "   - fname: is the filesystem location of the image\n",
    "   - radec: is the location of the galxy in the sky\n",
    "This notebook will focus on the asymmetry parameters; A, As, and As90.\n",
    "The next notebook will introduce the other measures of galaxy morphology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the \"needle galaxy\" in the universe \n",
    "We introduced the asymmetry measures A, and As in the last notebook. To refresh your memory, A is better at finding the asymmery of the internal stuctures of galaxies, where as As is better at finding asymmetry in the overall shape of a galaxy and does not anayse the internal structure at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Make sure to use appropriate labels and titles in your plots.\n",
    "1. Make a scatter plot of A vs As\n",
    "2. Make histogram plots of A, and As.\n",
    "3. By inspection of the above plots, define thresholds for A, and As in which the majortiy of points fall under. Then split the dataset into major and minority subsets. Plot these subsets as you did in Q1, but explicitly colouring the different subsets. You may want to use the np.where() command or the pandas query command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating outliers\n",
    "One common method of ad-hoc analysis Astronomers use is looking at extreme outliers. You may be used at trying to get rid of exteme outliers from the data you've worked with in the past as usuaually these were caused by some source of noise or systematic error. Therefore you would normally run the experiments several more times to reduce the effect of noise or investigate the experiment for sources of systematic error in order to eliminate them.\n",
    "However, exteme outliers may also indicate some interesting physics! This exercise will investigate these outliers.\n",
    "\n",
    "## Exercise\n",
    "    1. Using your knowledge of what A measures, what types of galaxies would you expect to have large A, and\n",
    "    small A?\n",
    "    2. Take galaxies with the 5 largest A, and 5 largest As and plot the colour images of them alongside their            masks. You may want to use the below code snippet to help you get started.\n",
    "    3. Pick some more outliers (no more than 10 maximum) and plot these as before. Write down your rational for picking these outliers. \n",
    "    4. For each galaxy you plotted comment on whether it is actually an interesting galaxy. For example is it a          morphological disturbed galaxy, or is just a normal galaxy which has been contaminated by a nearby star or        some other artifact? \n",
    "#### Caution some of the plotted masks may be flipped in the horizonbtal or vertical axes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for use in Q2\n",
    "width, height = 128, 128\n",
    "scale = 60. / width #  set image scale to that of 1 arcmin\n",
    "# get colour image\n",
    "image = SkyServer.getJpegImgCutout(ra=ra, dec=dec, width=width, height=height, scale=scale, dataRelease='DR16')\n",
    "\n",
    "# get science image\n",
    "image = Image.readImage(filename=fname, ra=ra, dec=dec)\n",
    "sky, skyerr, *rest = skyBackground.skybgr(image)\n",
    "# get image mask\n",
    "mask = pixmap.pixelmap(image, sky+skyerr, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contamination\n",
    "\n",
    "By now you should understand that morphologically disturbed galaxies are hard to find! There are a lot of false positives where various external light sources contaminate the glaxies light, tricking our measurments into beleiving that they are asymmetric when its just a bright nearby star in the way. \n",
    "We can in princple remove these nearby stars by using a catalog of star locations. However, this tends to remove some pixels that belong to the galaxy, meaning that we are loosing data or worse biasing our calculations!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
